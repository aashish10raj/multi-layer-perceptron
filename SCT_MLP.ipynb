{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "SCT_MLP.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpw-ykVKs-TC"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kna1tPGps-TR"
      },
      "source": [
        "**Goal 1: Create perceptron**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWBWmiUbs-TU"
      },
      "source": [
        "def perceptron(x, W, b):\n",
        "    '''\n",
        "    Input: weights W, biases b, input activations x\n",
        "    Output: Single hypothesis\n",
        "    '''\n",
        "    z = np.sum(W.T * x) + b\n",
        "    return sigmoid(z)\n",
        "\n",
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "def deriv_sigmoid(z):\n",
        "    return sigmoid(z) * (1-sigmoid(z))"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPEiOheds-TW",
        "outputId": "f489412a-c097-4f01-fbe1-88426268587c"
      },
      "source": [
        "activations = np.array([0.3, 0.1, 0.7, 8])\n",
        "weights = np.random.rand(activations.shape[0])\n",
        "bias = 1\n",
        "\n",
        "perceptron(activations, weights, bias)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9921509518294168"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kd1S2x5Gs-TZ"
      },
      "source": [
        "**Goal 2: Get, Clean, & Normalize Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfiQh9_6s-Ta",
        "outputId": "6d64970e-fbca-4c5f-9e80-e6137b8d760e"
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv(\"housepricedata.csv\")\n",
        "print(data.head())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   LotArea  OverallQual  OverallCond  ...  Fireplaces  GarageArea  AboveMedianPrice\n",
            "0     8450            7            5  ...           0         548                 1\n",
            "1     9600            6            8  ...           1         460                 1\n",
            "2    11250            7            5  ...           1         608                 1\n",
            "3     9550            7            5  ...           1         642                 0\n",
            "4    14260            8            5  ...           1         836                 1\n",
            "\n",
            "[5 rows x 11 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_6FUo3Qs-Td",
        "outputId": "7d60bdf4-93c0-4364-a292-8fe64e93f662"
      },
      "source": [
        "houses = data.values # DataFrame --> Array\n",
        "x = houses[:, :-1] # Input Activations\n",
        "y = houses[:, -1] # Output labels (0 or 1)\n",
        "print(x)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 8450     7     5 ...     8     0   548]\n",
            " [ 9600     6     8 ...     6     1   460]\n",
            " [11250     7     5 ...     6     1   608]\n",
            " ...\n",
            " [ 9042     7     9 ...     9     2   252]\n",
            " [ 9717     5     6 ...     5     0   240]\n",
            " [ 9937     5     6 ...     6     0   276]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TU0oOzvps-Tf"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "x = MinMaxScaler().fit(x).transform(x) # features between 0 and 1"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBxmcLZes-Tg"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_valtest, Y_train, Y_valtest = train_test_split(x, y, test_size=0.3) # 70% Train\n",
        "X_val, X_test, Y_val, Y_test = train_test_split(X_valtest, Y_valtest, test_size=0.5) # 15% to test and val"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzUuj79zs-Th",
        "outputId": "4484cf00-3b9e-45eb-9fb6-1a2bb462d039"
      },
      "source": [
        "print(X_train.shape)\n",
        "print(X_val.shape)\n",
        "print(X_test.shape)\n",
        "print(x.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1022, 10)\n",
            "(219, 10)\n",
            "(219, 10)\n",
            "(1460, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5DW7jfLs-Tj"
      },
      "source": [
        "**Goal 3: Forward Propagation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tx1EMsqls-Tk"
      },
      "source": [
        "#np.random.seed(0)\n",
        "def forwardProp(activations, weights, biases, zArr, numLayers):\n",
        "    '''\n",
        "    Vectorized Implementation\n",
        "    Input: First Layer activations, weights, biases, number of layers\n",
        "    Output: Last layer\n",
        "    '''\n",
        "    # Layer i\n",
        "    for i in range(numLayers-1):\n",
        "        z = np.dot(weights[i], activations[i]) + biases[i]\n",
        "        zArr.append(z)\n",
        "        activations.append(sigmoid(z))\n",
        "\n",
        "params = {\n",
        "    \"weights\": [\n",
        "    np.random.randn(X_train.shape[0], X_train.shape[1]) * np.sqrt(2/X_train.shape[0]), # l1\n",
        "    np.random.randn(1, X_train.shape[0]) * np.sqrt(2/X_train.shape[0])  # l2\n",
        "    ],\n",
        "    \n",
        "    \"biases\": 2,    \n",
        "    \n",
        "    \"numLayers\": 3 \n",
        "}\n",
        "\n",
        "numLayers = 3\n",
        "zArr = []\n",
        "activations = [X_train.T]\n",
        "weights = [\n",
        "    np.random.randn(X_train.shape[0], X_train.shape[1]) * np.sqrt(2/X_train.shape[0]), # l1\n",
        "    np.random.randn(1, X_train.shape[0]) * np.sqrt(2/X_train.shape[0])  # l2\n",
        "          ]\n",
        "biases = np.ones(numLayers-1) # bias in each layer except output\n",
        "\n",
        "forwardProp(activations, weights, biases, zArr, numLayers)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QUBm8Qhs-Tl",
        "outputId": "8f715284-6aae-49da-c2f8-dc201032122b"
      },
      "source": [
        "def backwardProp(activations, weights, biases, numLayers, actual, zArr, weightDecay, learning_rate):\n",
        "    # Compute Cost\n",
        "    cost = np.mean(1/2 * np.linalg.norm(activations[-1]-actual) ** 2)\n",
        "    for layer in range(numLayers - 1):\n",
        "        for i in range(activations[layer].shape[0]):\n",
        "            for j in range(activations[layer+1].shape[0]):\n",
        "                cost += weights[layer][j][i] ** 2\n",
        "    cost *= weightDecay / 2\n",
        "    print(cost)\n",
        "    \n",
        "    # Output layer delta\n",
        "    deltas = {}\n",
        "    delta_nL = np.multiply(-(actual - activations[-1]), deriv_sigmoid(zArr[-1]))\n",
        "    deltas[2] = delta_nL\n",
        "    \n",
        "    # Go through hidden layers (l2 --> index 1)\n",
        "    for l in range(numLayers-2, 0, -1): \n",
        "        deltas[l] = np.dot(weights[l].T, deltas[l+1]) * deriv_sigmoid(zArr[l])\n",
        "        deriv_W = np.dot(deltas[l+1], activations[l].T)\n",
        "        deriv_b = deltas[l+1]\n",
        "        \n",
        "        print(deriv_W)\n",
        "        weights[l] = weights[l] - learning_rate * deriv_W\n",
        "        # todo: update biases\n",
        "    \n",
        "weightDecay = 0.5\n",
        "learning_rate = 0.001\n",
        "backwardProp(activations, weights, biases, numLayers, Y_train, zArr, weightDecay, learning_rate)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "53.423091937847055\n",
            "[[32.86547733 32.78740671 32.67062488 ... 32.93326428 32.79740754\n",
            "  32.50004513]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLyu33Tls-Tn",
        "outputId": "fa98a76e-a68e-4f06-cb4f-e6805c04ac20"
      },
      "source": [
        "def runNetwork(activations, weights, biases, numLayers, actual, zArr, weightDecay, learning_rate):\n",
        "    epochs = 10\n",
        "    for x in range(epochs):\n",
        "        forwardProp(activations, weights, biases, zArr, numLayers)\n",
        "        backwardProp(activations, weights, biases, numLayers, Y_train, zArr, weightDecay, learning_rate)\n",
        "    \n",
        "runNetwork(activations, weights, biases, numLayers, Y_train, zArr, weightDecay, learning_rate)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "69.75010210067936\n",
            "[[-5.21889777e-08 -5.16251024e-08 -5.17567474e-08 ... -5.27003481e-08\n",
            "  -5.21971824e-08 -5.13483500e-08]]\n",
            "69.75010209983735\n",
            "[[-5.21889797e-08 -5.16251044e-08 -5.17567494e-08 ... -5.27003501e-08\n",
            "  -5.21971844e-08 -5.13483520e-08]]\n",
            "69.75010209899575\n",
            "[[-5.21889818e-08 -5.16251064e-08 -5.17567514e-08 ... -5.27003522e-08\n",
            "  -5.21971865e-08 -5.13483540e-08]]\n",
            "69.75010209815407\n",
            "[[-5.21889838e-08 -5.16251084e-08 -5.17567534e-08 ... -5.27003542e-08\n",
            "  -5.21971885e-08 -5.13483560e-08]]\n",
            "69.7501020973124\n",
            "[[-5.21889858e-08 -5.16251104e-08 -5.17567554e-08 ... -5.27003563e-08\n",
            "  -5.21971905e-08 -5.13483579e-08]]\n",
            "69.75010209647048\n",
            "[[-5.21889878e-08 -5.16251124e-08 -5.17567574e-08 ... -5.27003583e-08\n",
            "  -5.21971925e-08 -5.13483599e-08]]\n",
            "69.7501020956288\n",
            "[[-5.21889899e-08 -5.16251144e-08 -5.17567595e-08 ... -5.27003603e-08\n",
            "  -5.21971946e-08 -5.13483619e-08]]\n",
            "69.75010209478705\n",
            "[[-5.21889919e-08 -5.16251164e-08 -5.17567615e-08 ... -5.27003624e-08\n",
            "  -5.21971966e-08 -5.13483639e-08]]\n",
            "69.75010209394507\n",
            "[[-5.21889939e-08 -5.16251184e-08 -5.17567635e-08 ... -5.27003644e-08\n",
            "  -5.21971986e-08 -5.13483659e-08]]\n",
            "69.75010209310338\n",
            "[[-5.21889959e-08 -5.16251204e-08 -5.17567655e-08 ... -5.27003665e-08\n",
            "  -5.21972006e-08 -5.13483679e-08]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9svsSdWRs-To",
        "outputId": "c62a2b85-3d95-4160-8230-5933055c2bca"
      },
      "source": [
        "print(weights)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([[ 0.00769028,  0.03662686, -0.02912688, ...,  0.14495106,\n",
            "        -0.00359307,  0.01855318],\n",
            "       [-0.06757856, -0.03443372,  0.04046309, ..., -0.06455656,\n",
            "        -0.07165728, -0.01360764],\n",
            "       [ 0.02210058,  0.00506475,  0.02423172, ..., -0.01267709,\n",
            "         0.01681209,  0.04267638],\n",
            "       ...,\n",
            "       [-0.00819039,  0.05742223, -0.06916011, ...,  0.06841757,\n",
            "        -0.03969034,  0.00594728],\n",
            "       [ 0.05264275,  0.0436624 ,  0.00443696, ..., -0.07889662,\n",
            "         0.06002359, -0.06170833],\n",
            "       [ 0.01759781,  0.01615675, -0.01995902, ...,  0.02891982,\n",
            "        -0.09179208, -0.07777958]]), array([[-0.17872026,  0.01576308,  0.00265071, ..., -0.10429233,\n",
            "        -0.00093296, -0.0465038 ]])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWpPL1Jls-To"
      },
      "source": [
        "**References**\n",
        "1. http://ufldl.stanford.edu/tutorial/supervised/MultiLayerNeuralNetworks/\n",
        "2. https://towardsdatascience.com/weight-initialization-techniques-in-neural-networks-26c649eb3b78\n",
        "3. https://medium.com/@vdpatel/implementing-a-multi-layer-perceptron-neural-network-in-python-b22b5a3bdfa3\n",
        "4. https://www.codeproject.com/articles/821348/multilayer-perceptron-in-python\n",
        "5. https://www.allaboutcircuits.com/technical-articles/how-to-create-a-multilayer-perceptron-neural-network-in-python/\n",
        "6. https://vitalflux.com/perceptron-explained-using-python-example/"
      ]
    }
  ]
}